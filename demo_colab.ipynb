{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meS72RkI8hN7",
        "outputId": "a1f17ee4-e51c-46a4-d1b3-1e0b3670e9db"
      },
      "source": [
        "# change user and pwd with your username and password in github\n",
        "#!git clone https://user:pwd@github.com/dorukuzucu/deep_learning_interim_project.git\n",
        "\n",
        "# colab initialize pwd to /content\n",
        "# we need to change directory to our project to acces the data\n",
        "%cd deep_learning_interim_project/\n",
        "\n",
        "#download data\n",
        "#! wget https://storage.cloud.google.com/physionet-challenge-2020-12-lead-ecg-public/PhysioNetChallenge2020_Training_CPSC.tar.gz\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep_learning_interim_project'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 269 (delta 11), reused 20 (delta 5), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (269/269), 41.79 MiB | 31.56 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n",
            "/content/deep_learning_interim_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l6mbtUvEc4lA",
        "outputId": "1f33c5d1-5f44-4fd3-8e40-69c2bc39ad35"
      },
      "source": [
        "!pip install -r requirements.txt\r\n",
        "# after venv is done you need to restart the runtime"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting matplotlib==3.3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/43/2bd63467490036697e7be71444fafc7b236923d614d4521979a200c6b559/matplotlib-3.3.3-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6MB 5.1MB/s \n",
            "\u001b[?25hCollecting petastorm==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/2c/22c332dee5679e4de091ff613a90eb599f4924e51d766d538aa165aa1893/petastorm-0.9.8-py2.py3-none-any.whl (282kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.7.* in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.7.0+cu101)\n",
            "Collecting scipy==1.5.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision==0.8.* in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.8.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.*->-r requirements.txt (line 1)) (1.19.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.*->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.*->-r requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.*->-r requirements.txt (line 1)) (7.0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.*->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.*->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from petastorm==0.9.*->-r requirements.txt (line 2)) (1.15.0)\n",
            "Collecting pyspark>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2MB 57kB/s \n",
            "\u001b[?25hCollecting pyarrow>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |████████████████████████████████| 17.7MB 218kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from petastorm==0.9.*->-r requirements.txt (line 2)) (1.1.5)\n",
            "Requirement already satisfied: dill>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from petastorm==0.9.*->-r requirements.txt (line 2)) (0.3.3)\n",
            "Requirement already satisfied: pyzmq>=14.0.0 in /usr/local/lib/python3.6/dist-packages (from petastorm==0.9.*->-r requirements.txt (line 2)) (20.0.0)\n",
            "Requirement already satisfied: psutil>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from petastorm==0.9.*->-r requirements.txt (line 2)) (5.4.8)\n",
            "Requirement already satisfied: packaging>=15.0 in /usr/local/lib/python3.6/dist-packages (from petastorm==0.9.*->-r requirements.txt (line 2)) (20.8)\n",
            "Collecting diskcache>=3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/a0/533c95dd971aab855eba8605694b21f5b401ec52ad67145b6f8b4042dd67/diskcache-5.1.0-py3-none-any.whl (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.10.2 in /usr/local/lib/python3.6/dist-packages (from petastorm==0.9.*->-r requirements.txt (line 2)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.*->-r requirements.txt (line 3)) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.*->-r requirements.txt (line 3)) (0.8)\n",
            "Collecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.0->petastorm==0.9.*->-r requirements.txt (line 2)) (2018.9)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612242 sha256=982e19227c86040c5128e0619b5ced4cfeb9644f0a20fc2afdaaa4ce4b0138ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
            "Successfully built pyspark\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: matplotlib, py4j, pyspark, pyarrow, diskcache, petastorm, scipy\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed diskcache-5.1.0 matplotlib-3.3.3 petastorm-0.9.8 py4j-0.10.9 pyarrow-2.0.0 pyspark-3.0.1 scipy-1.5.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4YdowNGhTlj",
        "outputId": "3bb3ab43-e6a2-4a97-ab3d-2a64e81d58f4"
      },
      "source": [
        "%cd deep_learning_interim_project"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep_learning_interim_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMC1AMutekml"
      },
      "source": [
        "from src.model import train"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB548__1iQ-q"
      },
      "source": [
        "#config = train.DUMMY_PARAMS\r\n",
        "config = {\r\n",
        "    'learning_rate': [0.05], # a float\r\n",
        "    'batch_size': [100], # an integer\r\n",
        "    'epochs': [50], # an integer\r\n",
        "    'optimizer_type': [\"Adam\"], # [\"Adam\", \"SGD\"]\r\n",
        "    'loss_fn': [\"penalty_mse\"], # [\"ce_loss\", \"penalty_l1\", \"penalty_mse\"]\r\n",
        "    'epochs_for_val': [5], # an integer\r\n",
        "    'weight_decay': [1e-2], # a float\r\n",
        "    'momentum': [0], # a float\r\n",
        "    'device':[\"cuda\"]\r\n",
        "}\r\n",
        "model = train.ECGHeartbeat() # ArrhythmiaNet, ECGHeartbeat, ECGNet, Model_2, Model_Ann"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "mwpJrgyKhVd3",
        "outputId": "703a36a0-e7ee-4cb5-c64b-f5bdda8c2852"
      },
      "source": [
        "mngr = train.TrainManager(model=model, processed_data_path=train.DATA_PATH, training_config=config, run_name=\"ECGHeartbeat\")\r\n",
        "mngr.train()\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting new run\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/deep_learning_interim_project/src/model/train.py:176: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n",
            "/usr/local/lib/python3.6/dist-packages/petastorm/arrow_reader_worker.py:53: FutureWarning: Calling .data on ChunkedArray is provided for compatibility after Column was removed, simply drop this attribute\n",
            "  column_as_pandas = column.data.chunks[0].to_pandas()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run:['penalty_mse', 'Adam', 0.05, 0.01] Epoch:0 Loss:287.5677104071997 Accuracy:0.0524930930140771\n",
            "Validating model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3a6a36a8d607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mECGHeartbeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmngr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_data_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDUMMY_PARAMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ECGHeartbeat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/deep_learning_interim_project/src/model/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m                         \u001b[0mtotal_predictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vG15OvYh9Dr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}